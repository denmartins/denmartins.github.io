{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e60aa925",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# LLM Pretraining\n",
    "\n",
    "## [Tópicos em Ciência de Dados](https://denmartins.github.io/teaching/2025-topicos-cd)\n",
    "\n",
    "### [Prof. Dr. Denis Mayr Lima Martins](https://denmartins.github.io/)\n",
    "\n",
    "### [Pontifícia Universidade Católica de Campinas](https://www.puc-campinas.edu.br/)\n",
    "\n",
    "<img src=\"https://www.puc-campinas.edu.br/wp-content/uploads/2022/06/logo-puc.png\" width=\"100px\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8405f1b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Objetivos de Aprendizagem\n",
    "\n",
    "- Compreender o conceito de Foundation Models e suas aplicações.\n",
    "- Entender a importância de pré-treinamento na criação de Large Language Models (LLMs)\n",
    "- Compreender os princípios e práticas de pré-treinamento de LLMs.\n",
    "- Implementar pré-treinamento de um modelo GPT-2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64e84d4-8bd3-4620-8a55-f86b58c4e567",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<center>\n",
    "<table style=\"width:100%\">\n",
    "<tr>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "Baseado no Livro <a href=\"http://mng.bz/orYv\">Build a Large Language Model From Scratch</a> de <a href=\"https://sebastianraschka.com\">Sebastian Raschka</a><br>\n",
    "<br>Code repository: <a href=\"https://github.com/rasbt/LLMs-from-scratch\">https://github.com/rasbt/LLMs-from-scratch</a>\n",
    "</td>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<a href=\"http://mng.bz/orYv\"><img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/cover-small.webp\" width=\"200px\"></a>\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf66a24",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<center>\n",
    "\n",
    "## Qual o **maior** problema em depender **apenas** de aprendizado **supervisionado** tradicional?\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495f946e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "<div style='align: left; text-align:center;'>\n",
    "    <img src='https://macgence.com/wp-content/uploads/2024/04/Healthcare-Datasets-Solutions-1024x683.webp' alt='Healthcare data' style=\"width:500px;\"/>\n",
    "    <span style='display:block;'>Dados anotados (labeled data) na área da Saúde são caros e difíceis de obter em larga escala. Fonte: <a href=\"https://macgence.com/blog/healthcare-dataset/\" target=\"_blank\">Macgence</a>.</span>\n",
    "    <br/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a0f1a1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Treinamento Supervisionado Tradicional\n",
    "\n",
    "*   **Escassez de Dados Rotulados:** Obter dados rotulados é caro e demorado.\n",
    "*   **Generalização Limitada:** Modelos treinados em datasets específicos podem ter dificuldades para generalizar para novos cenários.\n",
    "*   **Necessidade de Engenharia de Features:** Requer conhecimento especializado para selecionar e criar features relevantes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97c47f9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Foundation Models\n",
    "\n",
    "*   **Conceito:** Modelos treinados em grandes volumes de dados *não rotulados* que podem ser adaptados para uma variedade de tarefas downstream.\n",
    "*   **Características:**\n",
    "    *   **Escalabilidade:** Treinados em datasets massivos.\n",
    "    *   **Representação**: Aprendem a representar dados capturando nuances intrínsecas que ajudam a generalizar para outras tarefas.\n",
    "    *   **Adaptabilidade:** Podem ser finamente ajustados (fine-tuned) para tarefas específicas.\n",
    "    *   **Emergência de Capacidades:** Demonstram habilidades que não foram explicitamente programadas.\n",
    "*   **Analogia:** Aprender a ler e escrever antes de se especializar em um gênero literário específico."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c20ebc4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Foundation Models\n",
    "\n",
    "\n",
    "<div style='align: left; text-align:center;'>\n",
    "    <img src='https://blogs.nvidia.com/wp-content/uploads/2023/03/Transformer-apps.jpg' alt='Foundation Model' style=\"width:500px;\"/>\n",
    "    <span style='display:block;'>Foundation Model. Fonte: <a href=\"https://arxiv.org/pdf/2108.07258\" target=\"_blank\">On the Opportunities and Risks of Foundation Models</a>.</span>\n",
    "    <br/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8456137",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Foundation Models na Medicina\n",
    "\n",
    "\n",
    "\n",
    "<div style='align: left; text-align:center;'>\n",
    "    <img src='https://arxiv.org/html/2406.10729v3/x2.png' alt='Learning architecture, model size, and training data used by representative foundation models' style=\"width:500px;\"/>\n",
    "    <span style='display:block;'>Learning architecture, model size, and training data used by representative foundation models. Fonte: <a href=\"https://arxiv.org/html/2406.10729v3\" target=\"_blank\">A Comprehensive Survey of Foundation Models in Medicine</a>.</span>\n",
    "    <br/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845b4942-552e-4a64-91e0-e85eaf18e03d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<center>\n",
    "\n",
    "## O quão fácil é utilizar um modelo pré-treinado?\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4b6125-22e4-4439-ad45-975ea7850196",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## O quão fácil é utilizar um modelo pré-treinado?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdadf70-e21e-4a6e-9ccc-68fcf2884ee5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "generator = pipeline('text-generation', model='gpt2', truncation=True)\n",
    "set_seed(42)\n",
    "generator(\"Hello, I'm a language model,\", max_length=5, num_return_sequences=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343002bc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Foundation Models: Objetivos\n",
    "\n",
    "*   **Masked Language Modeling (MLM):** (Ex: BERT)\n",
    "    *   Ocultar aleatoriamente algumas palavras no texto e treinar o modelo para prever as palavras ocultas.\n",
    "    * **Loss:** Cross‑Entropy sobre posições mascaradas.\n",
    "*   **Causal Language Modeling (CLM):** (Ex: GPT)\n",
    "    *   Treinar o modelo para prever a próxima palavra em uma sequência.\n",
    "    *   **Loss:** Cross‑Entropy sobre todas as posições, com máscara causal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34496552",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Foundation Models: Tipos\n",
    "\n",
    "* **Embedding Extractiors**: Transformam dados de entrada em uma representação mais apropriada que preserva as características mais relevantes.\n",
    "* **Zero-Shot Models**: Executam a tarefa diretamente sobre dados não vistos durante o (pré-)treinamento. Operam sob o princípio de que, mesmo que um modelo não tenha visto um objeto específico durante o treinamento, ele deve conseguir usar seu conhecimento sobre outros objetos semelhantes para identificar o novo.\n",
    "- Exemplos: [Meta Segment Anything Model (SAM)](https://segment-anything.com/), [OpenAI CLIP](https://openai.com/index/clip/), [Meta DINOv2](https://dinov2.metademolab.com/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726dc5da-9c50-4897-a6e8-f6baf5eead32",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Foundation Models e Especialistas em Dados (cont.)\n",
    "\n",
    "<div style='align: left; text-align:center;'>\n",
    "    <img src='https://figures.semanticscholar.org/58aacb967cc7fc25cfc9d51b7ad3e57ac00d119b/1-Figure1-1.png' style=\"width:500px;\"/>\n",
    "    <span style='display:block;'>Transformando dados com Foundation Models. Fonte: <a href=\"https://arxiv.org/abs/2205.09911\" target=\"_blank\">Can Foundation Models Wrangle Your Data?</a></span>\n",
    "    <br/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49410b7-b9c1-40d4-935d-36e85d52f962",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Foundation Models e Especialistas em Dados\n",
    "\n",
    "\n",
    "<div style='align: left; text-align:center;'>\n",
    "    <img src='https://figures.semanticscholar.org/0cb4e7546d955a1d635da154f0d82ab05cddcf14/1-Figure1-1.png' style=\"width:500px;\"/>\n",
    "    <span style='display:block;'>Integração/Harmonização de Dados via Agentes de LLM. Fonte: <a href=\"https://arxiv.org/abs/2502.07132\" target=\"_blank\">Interactive Data Harmonization with LLM Agents: Opportunities and Challenges</a>.</span>\n",
    "    <br/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c3ede3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Datasets de Pré-treinamento\n",
    "\n",
    "*   **Common Crawl:** Um vasto repositório de páginas da web.\n",
    "*   **Wikipedia:** Uma enciclopédia colaborativa online.\n",
    "*   **BooksCorpus:** Um conjunto de livros digitais.\n",
    "*   **The Pile:** Uma coleção diversificada de datasets textuais.\n",
    "*   Project Gutenberg, arXiv, PubMed  \n",
    "*   Código (GitHub, GitLab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed5dbbf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Limpeza de dados\n",
    "  \n",
    "- Remover duplicatas, HTML tags, scripts.  \n",
    "- Filtrar linguagem e conteúdo ofensivo.  \n",
    "- Normalizar pontuação, acentos.\n",
    "- Balanceamento de domínio (ex.: código > texto natural).  \n",
    "- Equalização de gêneros, regiões geográficas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea28d65",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "## Avaliação de Pré-Treinamento\n",
    "\n",
    "| Benchmark | Métrica principal | Observação |\n",
    "|-----------|-------------------|------------|\n",
    "| GLUE      | Accuracy (avg)    | Tarefas de compreensão textual |\n",
    "| SuperGLUE | Weighted F1       | Tarefas mais difíceis |\n",
    "| LAMBADA   | Accuracy          | Previsão do último token em sentenças longas |\n",
    "| MMLU      | Accuracy          | 57 domínios acadêmicos |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c95d15",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Desafios e Considerações Éticas\n",
    "\n",
    "*   **Viés nos Dados:** Os modelos podem herdar vieses/preconceitos presentes nos dados de treinamento.\n",
    "* **Desinformação:** Capacidade de gerar texto convincente pode ser mal‑uso. \n",
    "* **Privacidade:** Modelos podem memorizar trechos sensíveis.  \n",
    "*   **Custo Computacional:** O pré-treinamento e o fine-tuning de LLMs exigem recursos computacionais significativos.\n",
    "*   **Impacto Ambiental:** Consumo energético e emissões de CO₂ no treinamento. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9eb7f0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<div style='align: left; text-align:center;'>\n",
    "    <img src='https://specials-images.forbesimg.com/imageserve/5f3c7a3ef99cba8bd510dbc9/Training-an-AI-model-can-have-an-enormous-carbon-footprint-/960x0.png?fit=scale' alt='Impacto Ambiental da AI' style=\"width:500px;\"/>\n",
    "    <span style='display:block;'>Impacto Ambiental da AI. Fonte: <a href=\"https://www.forbes.com/sites/glenngow/2020/08/21/environmental-sustainability-and-ai/\" target=\"_blank\">Forbes</a>.</span>\n",
    "    <br/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ca5a5d-e056-40de-817d-40e535356c15",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Resumo\n",
    "\n",
    "* LLMs são Foundation Models específicos para geração de texto.  \n",
    "* Pré‑treinamento exige grande escala de parâmetros, dados e GPU.  \n",
    "* Ética não pode ser tratada como complemento; é parte integrante do design.\n",
    "* Impacto Ambiental: https://hbr.org/2024/07/the-uneven-distribution-of-ais-environmental-impacts\n",
    "* Leituras recomendadas:\n",
    "    - [A Dataset-Centric Survey of LLM-Agents for Data Science](https://openreview.net/pdf?id=W4hexmqgoN)\n",
    "    - [How Do Data Analysts Respond to AI Assistance? A Wizard-of-Oz Study](https://dl.acm.org/doi/pdf/10.1145/3613904.3641891)\n",
    "    - [The Uneven Distribution of AI’s Environmental Impacts](https://hbr.org/2024/07/the-uneven-distribution-of-ais-environmental-impacts)\n",
    "* Pergunta: Qual aspecto do pré‑treinamento você considera mais crítico para o desempenho de um LLM? Por que?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ae2109-fd95-4b44-9586-0276b807b053",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<div style='align: left; text-align:center;'>\n",
    "    <img src='https://figures.semanticscholar.org/2fe74a07051649cb5dc41da319fef547647e9171/9-Figure3-1.png' alt='Impacto Ambiental da AI' style=\"width:600px;\"/>\n",
    "    <span style='display:block;'>Analista de Dados e Agentes de LLM. Fonte: <a href=\"https://dl.acm.org/doi/pdf/10.1145/3613904.3641891\" target=\"_blank\">How Do Data Analysts Respond to AI Assistance? A Wizard-of-Oz Study</a>.</span>\n",
    "    <br/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d474eaf4-b088-4b32-962a-f67fc560919c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## GPT-2: Pré-treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f2f8142",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7331b1e7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.10.5\n",
      "numpy version: 2.3.2\n",
      "tiktoken version: 0.11.0\n",
      "torch version: 2.8.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\"matplotlib\", \n",
    "        \"numpy\", \n",
    "        \"tiktoken\", \n",
    "        \"torch\",\n",
    "       ]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "765936a3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "# Importamos todo o códigdo\n",
    "# desenvolvido nas aulas anteriores\n",
    "from llmdefinitions import GPTModel\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,   \n",
    "    \"context_length\": 256, \n",
    "    \"emb_dim\": 768,        \n",
    "    \"n_heads\": 12,         \n",
    "    \"n_layers\": 12,        \n",
    "    \"drop_rate\": 0.1,      \n",
    "    \"qkv_bias\": False      \n",
    "}\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8dabe6-ff55-4479-9909-6bbfa0a8874f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Usando GPT para gerar texto\n",
    "\n",
    "![](https://camo.githubusercontent.com/fa3e770f1936dfcf126f3f5c20345dbfea56e76421943f7ad86fcad92c5137ec/68747470733a2f2f73656261737469616e72617363686b612e636f6d2f696d616765732f4c4c4d732d66726f6d2d736372617463682d696d616765732f636830355f636f6d707265737365642f6770742d70726f636573732e77656270)\n",
    "\n",
    "A geração de texto envolve o encoding de texto para Token Ids e o processamento pelo modelo GPT com saída em forma de logits. Estes últimos são convertidos de volta a token IDs que, por sua vez, sofrem decoding para a representação textual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fda5e567",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6109, 3626, 6100,  345]])\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "from llmdefinitions import generate_text_simple\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "     # Adiciona a dimensão do batch\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "    return encoded_tensor\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = text_to_token_ids(start_context, tokenizer)\n",
    "\n",
    "print(token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "591a4f84",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6109,  3626,  6100,   345, 34245,  5139,  2492, 25405, 17434, 17853,\n",
       "          5308,  3398, 13174, 43071]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ids = generate_text_simple(\n",
    "    model=model,                   \n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7db0321",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Every effort moves you rentingetic wasnم refres RexMeCHicular stren'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "token_ids_to_text(token_ids, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505bfada-fdee-43ba-8310-21531903a313",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Geração de Texto\n",
    "![](https://camo.githubusercontent.com/ac88f12d51d22b53ea46690fe158914073d0e8d78194bca68a077470ca1ae87d/68747470733a2f2f73656261737469616e72617363686b612e636f6d2f696d616765732f4c4c4d732d66726f6d2d736372617463682d696d616765732f636830355f636f6d707265737365642f70726f62612d746f2d746578742e77656270)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9225e1-8a64-40cd-a113-ce22b995f417",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Considere os dois exemplos abaixo. Note que `targets` são as `inputs` deslocados em 1 posição. Esse deslocamento é crucial para ensinar o modelo a prever o próximo token em uma sequência."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "155d8b6f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs = torch.tensor(\n",
    "    [[16833, 3626, 6100], # [\"every effort moves\",\n",
    "    [40,    1107, 588]])  #  \"I really like\"]\n",
    "targets = torch.tensor([\n",
    "    [3626, 6100, 345  ],  # [\" effort moves you\",\n",
    "    [588,  428,  11311]]) #  \" really like chocolate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad979be7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "print(logits.shape)\n",
    "# Probabilidade para cada token no vocabulário\n",
    "probas = torch.softmax(logits, dim=-1)\n",
    "# Shape: (batch_size, num_tokens, vocab_size)\n",
    "print(probas.shape)\n",
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"Token IDs:\\n\", token_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6e0dd0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "O decoding dos token IDs mostra o que foi produzido pelo modelo. Note que o como ainda não treinamos o modelo, a geração de texto é bem ruim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c77589fe",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  Armed heNetflix\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e217f6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Loss de geração de texto\n",
    "\n",
    "<div style='align: left; text-align:center;'>\n",
    "    <img src='https://lena-voita.github.io/resources/lectures/lang_models/neural/one_step_loss_intuition-min.png' alt='Cross Entropy Loss' style=\"height:300px;\"/>\n",
    "    <span style='display:block;'>Cross Entropy Loss. Fonte: <a href=\"https://lena-voita.github.io/nlp_course/language_modeling.html\" target=\"_blank\">Lena Voita</a>.</span>\n",
    "    <br/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca306e77",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# Logits Shape: (batch_size, num_tokens, vocab_size)\n",
    "print(\"Logits shape:\", logits.shape)\n",
    "# Targets Shape: (batch_size, num_tokens)\n",
    "print(\"Targets shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c972f824",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "404dab3b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7722)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2046600f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Perplexity\n",
    "\n",
    "- Um conceito relacionado à *cross entropy loss* é a *perplexity* de um LLM, que é simplesmente a exponencial da cross entropy loss.\n",
    "- A perplexidade costuma ser considerada mais interpretável porque pode ser entendida como o tamanho efetivo do vocabulário sobre o qual o modelo tem incerteza em cada passo.\n",
    "- A perplexidade fornece uma medida de quão bem a distribuição de probabilidade prevista pelo modelo corresponde à distribuição real das palavras no conjunto de dados.\n",
    "- Semelhante à loss, uma perplexidade menor indica que as previsões do modelo estão mais próximas da distribuição observada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "000a07cb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(47678.8672)\n"
     ]
    }
   ],
   "source": [
    "perplexity = torch.exp(loss)\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d49b11f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Calculando loss de traino e validação"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c634ff4f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Para calcular a perda (loss) nos conjuntos de dados de treinamento e validação, utilizamos o pequeno conjunto de textos The Verdict, conto curto de Edith Wharton, com o qual já trabalhamos no início. \n",
    "\n",
    "Curiosidade: o modelo Llama 2‑7B precisou de 184.320 horas de GPU em GPUs A100 para ser treinado em 2 trilhões de tokens. Calculando o custo horário de um servidor em nuvem AWS com 8×A100 a aproximadamente 30 dóalres, treinar esse LLM custaria:  \n",
    "$\\text{custo} = \\frac{184\\,320}{8} \\times \\$30 = \\$690.000$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc17f9e-8ea8-4988-8ce0-bdabd9793820",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "file_path = \"the-verdict.txt\"\n",
    "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
    "if not os.path.exists(file_path):\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        text_data = response.read().decode('utf-8')\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(text_data)\n",
    "else:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        text_data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce534307-f9d9-4b00-a66d-ac929494a184",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f3f444",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Dividindo o dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15bd156",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<div style='align: left; text-align:center;'>\n",
    "    <img src='https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/batching.webp' alt='Dividindo o dataset' style=\"height:500px;\"/>\n",
    "    <span style='display:block;'>Dividindo o dataset em treino e validação. Fonte: Sebastian Raschka.</span>\n",
    "    <br/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "58e9ccad",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llmdefinitions import create_dataloader_v1\n",
    "\n",
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:] \n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1a6a6dc6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "\n",
    "if total_tokens * (train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the training loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"increase the `training_ratio`\")\n",
    "\n",
    "if total_tokens * (1-train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the validation loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"decrease the `training_ratio`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccba465d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Verificando os dataloaders\n",
    "\n",
    "Temos 9 batches de treinamento com 2 amostras e 256 tokens cada um. Como alocamos apenas 10\\% dos dados para validação, há apenas um lote de validação composto por 2 exemplos de entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f52a1f3c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d17f92be",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tokens: 4608\n",
      "Validation tokens: 512\n",
      "All tokens: 5120\n"
     ]
    }
   ],
   "source": [
    "train_tokens = 0\n",
    "for input_batch, target_batch in train_loader:\n",
    "    train_tokens += input_batch.numel()\n",
    "\n",
    "val_tokens = 0\n",
    "for input_batch, target_batch in val_loader:\n",
    "    val_tokens += input_batch.numel()\n",
    "\n",
    "print(\"Training tokens:\", train_tokens)\n",
    "print(\"Validation tokens:\", val_tokens)\n",
    "print(\"All tokens:\", train_tokens + val_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4badf13d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(\n",
    "        logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduzimos o número de batches para corresponder ao total de lotes no DataLoader.\n",
    "        # Se `num_batches` exceder a quantidade de batches disponível, faz-se essa correção\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ff35848f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_device(on_gpu=True):\n",
    "    has_mps = torch.backends.mps.is_available()\n",
    "    has_cuda = torch.cuda.is_available()\n",
    "    return \"mps\" if (has_mps and on_gpu) else \"cuda\" if (has_cuda and on_gpu) else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0c85ebac",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.98758316040039\n",
      "Validation loss: 10.98110580444336\n"
     ]
    }
   ],
   "source": [
    "device = set_device()\n",
    "model.to(device)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8f6edb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Pré-treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28894c28",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "![]()\n",
    "\n",
    "\n",
    "<div style='align: left; text-align:center;'>\n",
    "    <img src='https://camo.githubusercontent.com/7a232fecc385a11b71cf7e0d59b79a21345d3dd15c58e012a717cec80e1af613/68747470733a2f2f73656261737469616e72617363686b612e636f6d2f696d616765732f4c4c4d732d66726f6d2d736372617463682d696d616765732f636830355f636f6d707265737365642f747261696e2d73746570732e77656270' alt='Pré-treinamento' style=\"height:400px;\"/>\n",
    "    <span style='display:block;'>Pré-treinamento. Fonte: Sebastian Raschka.</span>\n",
    "    <br/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0545cc5a-9f07-40ba-bcf6-e75f539d74bc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, \n",
    "                       optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        \n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # Calculate loss gradients\n",
    "            optimizer.step() # Update model weights using loss gradients\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9be9d2e-49b4-4d0f-949b-bcc4ac4df715",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, \n",
    "                   val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(\n",
    "            train_loader, model, \n",
    "            device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(\n",
    "            val_loader, model, \n",
    "            device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2300cb-1743-4f69-ad4f-1c2764db7a39",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "        decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "        print(decoded_text.replace(\"\\n\", \" \"))\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a193704-6a9d-4723-b0a0-e13e73eebeef",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Treinando o modelo\n",
    "\n",
    "- Treinamos o `GPTModel` por 10 épocas usando um otimizador AdamW e a função `train_model_simple` que definimos anteriormente. \n",
    "- AdamW é uma variante do Adam que aprimora o método de *weight decay*, cujo objetivo é minimizar a complexidade do modelo e evitar overfitting, penalizando pesos maiores.\n",
    "- Para conjuntos de dados maiores, geralmente 1 ou 2 épocas são suficientes; aqui usamos 10 porque o conjunto de treinamento é muito pequeno, permitindo que o modelo aprenda algo útil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f1ed1a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), \n",
    "                              lr=0.0004, weight_decay=0.1)\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f1b0a5-42f9-4c2f-95a5-74639c068837",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "\n",
    "    # Create a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    #plt.savefig(\"loss-plot.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34d584f-7b5a-41ab-9ae4-78f1caf2aa95",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9a963b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Temperature scaling\n",
    "\n",
    "<div style='align: left; text-align:center;'>\n",
    "    <img src='https://cdn.prod.website-files.com/618399cd49d125734c8dec95/6639e35ce91c16b3b9564b2f_mxaIPcROZcBFYta1I0nzWjlGTgs-LxzUOE3p6Kbvf9qPpZzBh5AAZG7ciRtgVquhLTtrM8ToJdNd-ubXvuz8tRfrqBwSozWHCj457pm378buxz2-XrMfWzfSv3b793QP61kLxRKT299WP1gbas_E118.png' alt='Temperatura LLM' style=\"height:250px;\"/>\n",
    "    <span style='display:block;'>Temperature Scaling. Fonte: <a href=https://cdn.prod.website-files.com/618399cd49d125734c8dec95/6639e35ce91c16b3b9564b2f_mxaIPcROZcBFYta1I0nzWjlGTgs-LxzUOE3p6Kbvf9qPpZzBh5AAZG7ciRtgVquhLTtrM8ToJdNd-ubXvuz8tRfrqBwSozWHCj457pm378buxz2-XrMfWzfSv3b793QP61kLxRKT299WP1gbas_E118.png\" target=\"_blank\">Hopsworks.ai</a>.</span>\n",
    "    <br/>\n",
    "</div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7ee499",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Top-k sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e0f44c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<div style='align: left; text-align:center;'>\n",
    "    <img src='https://camo.githubusercontent.com/91e2cf67b9c112c7ee396326977aeefa8daaf7e5ea1600c6753443c02ef9afe8/68747470733a2f2f73656261737469616e72617363686b612e636f6d2f696d616765732f4c4c4d732d66726f6d2d736372617463682d696d616765732f636830355f636f6d707265737365642f746f706b2e77656270' alt='Top-k sampling' style=\"height:300px;\"/>\n",
    "    <span style='display:block;'>Top-k sampling. Fonte: Sebastian Raschka.</span>\n",
    "    <br/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8436d4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Combinando estratégias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5a1519b6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature, top_k=None):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "        # Aplica top-k sampling\n",
    "        if top_k is not None:\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(\n",
    "                logits < min_val, \n",
    "                torch.tensor(float('-inf')).to(logits.device), logits)\n",
    "        # Aplica temperature scaling\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
    "            \n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dfa7cfb9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you\"\". I it a,. his that \" my-- \"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc12c2a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "## Salvando e carregando pesos do modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2b68941d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7a077275",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(torch.load(\"model.pth\"))\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4a8d01b3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    }, \n",
    "    \"model_and_optimizer.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1602e458",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"model_and_optimizer.pth\")\n",
    "\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0005, weight_decay=0.1)\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "model.train();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "rise": {
   "enable_chalkboard": true,
   "height": "80%",
   "overlay": "",
   "reveal_shortcuts": {
    "chalkboard": {
     "clear": "ctrl-k"
    },
    "main": {
     "toggleOverview": "tab"
    }
   },
   "scroll": true,
   "slideNumber": "c/t",
   "theme": "white",
   "transition": "slide",
   "width": "80%"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
